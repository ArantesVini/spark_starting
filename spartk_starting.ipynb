{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.get('JAVA_HOME')\n",
    "os.environ.get('SPARK_HOME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/13 08:55:14 WARN Utils: Your hostname, Viniciuss-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 172.16.0.149 instead (on interface en0)\n",
      "23/06/13 08:55:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/13 08:55:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"Starting with Spark\") \\\n",
    "    .config('spark.ui.port', '4050') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.16.0.149:4050\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Starting with Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1062e34d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "|Will| 23|\n",
      "|Bill| 32|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Simple example, how to create a Spark DataFrame\n",
    "\n",
    "data = [('Will', '23'), ('Bill', '32')]\n",
    "colNames = ['name', 'age']\n",
    "df = spark.createDataFrame(data, colNames)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['root_cnpj',\n",
       " 'company_legal_name',\n",
       " 'legal_nature',\n",
       " 'responsible_qualification',\n",
       " 'company_share_capital',\n",
       " 'business_size',\n",
       " 'federative_entity_responsible']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the Brazil Receita Federal data about business registration number (CNPJ);\n",
    "\n",
    "business = spark.read.csv('data/empresas/', sep=';', inferSchema=True)\n",
    "\n",
    "business_col_names = ['root_cnpj', 'company_legal_name', 'legal_nature', 'responsible_qualification', \\\n",
    "    'company_share_capital', 'business_size', 'federative_entity_responsible']\n",
    "\n",
    "for index, col_name in enumerate(business_col_names):\n",
    "    business = business.withColumnRenamed(f\"_c{index}\", col_name)\n",
    "    \n",
    "business.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['root_cnpj',\n",
       " 'order_cnpj',\n",
       " 'cnpj_dv',\n",
       " 'id_hq_or_branch',\n",
       " 'company_fantasy_name',\n",
       " 'registration_status',\n",
       " 'date_registration_status',\n",
       " 'reason_registration_status',\n",
       " 'city_outside_name',\n",
       " 'country',\n",
       " 'activity_start_date',\n",
       " 'main_cnae',\n",
       " 'secundary_cnae',\n",
       " 'street_type',\n",
       " 'street',\n",
       " 'number',\n",
       " 'complement',\n",
       " 'neighborhood',\n",
       " 'zip_code',\n",
       " 'state_code',\n",
       " 'city',\n",
       " 'ddd_1',\n",
       " 'phone_1',\n",
       " 'ddd_2',\n",
       " 'phone_2',\n",
       " 'ddd_fax',\n",
       " 'fax',\n",
       " 'email',\n",
       " 'special_situation',\n",
       " 'date_special_situation']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "establishments = spark.read.csv('data/estabelecimentos/', sep=';', inferSchema=True)\n",
    "\n",
    "estab_col_names = ['root_cnpj', 'order_cnpj', 'cnpj_dv', 'id_hq_or_branch', 'company_fantasy_name',\\\n",
    "    'registration_status', 'date_registration_status', 'reason_registration_status', 'city_outside_name',\\\n",
    "        'country', 'activity_start_date', 'main_cnae', 'secundary_cnae',\\\n",
    "            'street_type', 'street', 'number', 'complement', 'neighborhood', 'zip_code', 'state_code', \\\n",
    "                'city', 'ddd_1', 'phone_1', 'ddd_2', 'phone_2', 'ddd_fax', 'fax', \\\n",
    "                    'email', 'special_situation', 'date_special_situation']\n",
    "\n",
    "for index, col_name in enumerate(estab_col_names):\n",
    "    establishments = establishments.withColumnRenamed(f\"_c{index}\", col_name)\n",
    "    \n",
    "establishments.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "partners = s\n",
    "\n",
    "partners_col_names = ['root_cnpj', 'partner_id', 'partner_name_or_legal_name', \\\n",
    "    'cnpj_cpf_partner', 'partner_qualificstion', 'entry_date_partnership', 'country', 'legal_representative',\\\n",
    "        'representative_name', 'legal_representative_qualification', 'age_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
